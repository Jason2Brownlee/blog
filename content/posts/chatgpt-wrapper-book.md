---
date: '2025-05-18T08:00:49+10:00'
title: 'Book as ChatGPT Wrapper'
---

I listened to an episode by Nicolas Cole on his "Coffee With Cole" podcast titled "_The AI Writing Trend No One Is Talking About_".

Here's the youtube version:

* [The AI Writing Trend No One Is Talking About](https://www.youtube.com/watch?v=VSawL8YRSlg)

The thesis of the episode is that non-fiction writers should stop publishing books and instead should use the material as prompts/context in ChatGPT wrapper apps to help the target audience to achieve a desired outcome.

Here's the thesis from the video according to Gemini 2.5 flash preview:

> The thesis of the YouTube episode is that AI is changing how non-fiction writers can monetize their knowledge, suggesting that writing books might no longer be the most profitable method. The video argues that non-fiction books can be seen as training prompts for AI and that writers have undervalued skills that can be better monetized through AI rather than traditional book writing. This shift in landscape is leading non-fiction writers to consider writing fewer books due to the opportunity cost.

It's a solid idea.

**The prompt version of a book can be a lot more helpful than the book.**

People with a problem don't want a book, they want the shortest path to a solution.

For example, I know a lot about how to fit and use xgboost models for predictive modelling (e.g. for regression, classification, time series, ec.).

- I could develop book about all of this. (I did write about this a long time ago, and a [website about this](https://xgboosting.com) more recently).
- Instead, I could use all of the material as context and prompts to help people develop and use xgboost predictive models.

I can see this be interesting, for example:

* Casual Q&A on each topic
* Worked examples as well as exercises on each topic
* Customization of topic to a specific dataset or problem
* Ongoing support/debugging for future real projects.

The context could include a corpus of:

* How to tutorials
* Worked examples
* Checklists
* Common errors

And on and on.

This could be coupled with a community for support and sharing.

And the corpus can be updated amended as more use cases come up.

I think this approach becomes more effective as the target outcome is more specific.

Perhaps not:

> "_learning how to develop and do predictive modelling with xgboost_"

But instead:

> "_help me develop the best xgboost model for my time series problem_"

Or something.

Now apply to specific niche topics.

Probably not technical topics, as it's too easy/competitive. Perhaps to less technical topics or less technical audiences.

